{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 1-1.Data 형태 확인\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2PWwy6-vCROh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Data 형태 확인\n",
        "df.shape\n",
        "\n",
        "# Data type 확인\n",
        "df.info()\n",
        "\n",
        "# Null 값 확인\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "hIJMHGd_Cm2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 1-1.Numeric(연속형) 변수 분포 확인\n",
        "---"
      ],
      "metadata": {
        "id": "eGOrimgqC8P1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "plt.style.use(['dark_background'])\n",
        "\n",
        "# displot 활용 분포 그리기 \n",
        "sns.displot(df['col']);\n",
        "\n",
        "# 분포의 평균도 같이 출력\n",
        "print(\"col :\", df['col'].mean())"
      ],
      "metadata": {
        "id": "t5Wj5k-_DCzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 1-1.Plot size 조절\n",
        "---"
      ],
      "metadata": {
        "id": "Nq-Q9_cuDMFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# (20, 5) → 가로 inch, 세로 inch\n",
        "plt.gcf().set_size_inches(20, 5)"
      ],
      "metadata": {
        "id": "oqEX8zlpDUuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 1-1.Unique한 Value별 카운팅\n",
        "---"
      ],
      "metadata": {
        "id": "97zhAh8XFDhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['col'].unique()"
      ],
      "metadata": {
        "id": "cy_CmL38Fbz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 1-2.산점도(Scatter plot) 그리기\n",
        "---"
      ],
      "metadata": {
        "id": "eQus9tZZFD_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "# x(가로), y(세로), hue(구분자)\n",
        "sns.scatterplot(x=df['x'], y=df['y'], hue = df['hue'])"
      ],
      "metadata": {
        "id": "ky8di45GFmgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 1-3.Train/Test set 분할\n",
        "---"
      ],
      "metadata": {
        "id": "EH73EmeoFEDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델링을 학습하기 위한 Fearue(X)와 Y데이터를 구분하는 단계 \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "X=df_merge.drop(['y'], axis=1)\n",
        "Y=df_merge['y']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, stratify=Y)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "gkg91IcKGCVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 1-3.모델 학습 및 예측\n",
        "---"
      ],
      "metadata": {
        "id": "qgJQWoRmFEGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 모델 학습\n",
        "rfc = RandomForestClassifier(random_state=123456)\n",
        "rfc.fit(x_train, y_train)\n",
        "\n",
        "# 예측\n",
        "# 예측은 학습에 사용된 Data와 Test Data 모두 예측하고 평가함(※ 과적합 여부 판별)\n",
        "y_pred_train = rfc.predict(x_train)\n",
        "y_pred_test = rfc.predict(x_test)\n"
      ],
      "metadata": {
        "id": "VneiAxiOGs0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 1-3.이진분류 모델 성능 확인\n",
        "---"
      ],
      "metadata": {
        "id": "9e1NBYWOFEKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(classification_report(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "ay-DWHLlIJgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 1-3.하이퍼 파라미터 튜닝\n",
        "---"
      ],
      "metadata": {
        "id": "OnjHNiMEFENP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = { 'n_estimators' : [400, 500],\n",
        "           'max_depth' : [6, 8, 10, 12]\n",
        "            }\n",
        "\n",
        "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
        "rf_clf = RandomForestClassifier(random_state = 123456, n_jobs = -1)\n",
        "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 3, n_jobs = -1, scoring='recall')\n",
        "grid_cv.fit(x_train, y_train)\n",
        "\n",
        "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
        "print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))"
      ],
      "metadata": {
        "id": "Yu7Stt_rITOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 1-3.중요 변수 파악(Feature Importance)\n",
        "---"
      ],
      "metadata": {
        "id": "7WI7FjPeFEQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "plt.style.use(['dark_background'])\n",
        "\n",
        "# rfc → 생성한 Model에 name 기재\n",
        "ftr_importances_values = rfc.feature_importances_\n",
        "ftr_importances = pd.Series(ftr_importances_values, index = x_train.columns)\n",
        "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.title('Feature Importances')\n",
        "sns.barplot(x=ftr_top20, y=ftr_top20.index)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IxGrnoSUJB_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 1-3.모델 Save & Read\n",
        "---"
      ],
      "metadata": {
        "id": "8qGAdPkEFEU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# 모델 저장\n",
        "saved_model = pickle.dumps(model)\n",
        "\n",
        "# 모델 Read\n",
        "model_from_pickle = pickle.loads(saved_model)"
      ],
      "metadata": {
        "id": "0dFdxKY2JT9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 2-1.특정 값 해당하는 DataFrame 출력\n",
        "---"
      ],
      "metadata": {
        "id": "UArJFm4bFEYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 숫자형\n",
        "df[df['col']== -200]\n",
        "\n",
        "# 문자형\n",
        "df[df['col']== '피자']"
      ],
      "metadata": {
        "id": "IXhU-FT-qyLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 2-1.DataFrame 특정값 치환\n",
        "---"
      ],
      "metadata": {
        "id": "sBjkFvT3FEcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df.replace(-200, np.NaN)"
      ],
      "metadata": {
        "id": "31RSPM3L0j6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 2-1.Null 값 이전 값으로 채워넣기\n",
        "---"
      ],
      "metadata": {
        "id": "mAM748I8FEgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "df.fillna(method='ffill') "
      ],
      "metadata": {
        "id": "C2II53qi03WY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 2-1.DataFrame 특정 col만 가져오기\n",
        "---"
      ],
      "metadata": {
        "id": "ITTUOZNIFEj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = df[['col1', 'col2']]"
      ],
      "metadata": {
        "id": "gZGplk6Yll_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 2-1.기본 line plot 그리기\n",
        "--- "
      ],
      "metadata": {
        "id": "NRLV9evtFEnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(df['x'], df['y'], label='label')"
      ],
      "metadata": {
        "id": "R1d1sr4Hl2rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 2-2.for문 활용 distplot 다중 출력\n",
        "--- "
      ],
      "metadata": {
        "id": "zw_L-buvFEqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 데이터에 i번째 데이터부터 출력\n",
        "for i in range(1,13):\n",
        "    plt.subplot(3,4,i)\n",
        "    plt.grid(False)\n",
        "    sns.distplot(df.iloc[:,i])\n",
        "\n",
        "plt.gcf().set_size_inches(20, 10)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J9rbTcdImBBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 2-2.다중 값 해당하는 DataFrame 출력\n",
        "--- "
      ],
      "metadata": {
        "id": "A7MSlMGBFEvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df[ (df['T'] >= 25) & (df['T'] <= 27) ]"
      ],
      "metadata": {
        "id": "AH3CGQ2xoWIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 2-3.Dataframe 유니크한 값 list 출력\n",
        "--- "
      ],
      "metadata": {
        "id": "bhTKrAF6FEy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df['col'].unique()"
      ],
      "metadata": {
        "id": "jbFkxuy4qCgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 2-3.Datetype(시간형)으로 변경하기\n",
        "--- "
      ],
      "metadata": {
        "id": "Gj0cIw9PFE2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# df['col']은 str type이여야함\n",
        "pd.to_datetime(df['col'])"
      ],
      "metadata": {
        "id": "GCzegxfJqSw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 2-3.DataFrame Index col값으로 만들기\n",
        "--- "
      ],
      "metadata": {
        "id": "ggFiD4luFE53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df.reset_index()"
      ],
      "metadata": {
        "id": "IQZUL4FhqfpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 3-1.이중 축 그래프 그리기\n",
        "--- "
      ],
      "metadata": {
        "id": "Ap3QmF6IFE9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.plot(df['x'], df['y'], color='green', label='label1')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(df['x'], df['y'], color='deeppink', label='label2')\n",
        "\n",
        "fig.legend()\n",
        "plt.gcf().set_size_inches(25, 5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qR2-DAo0qs4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 3-1.오름차순, 내림차순 정렬\n",
        "--- "
      ],
      "metadata": {
        "id": "Z-2V7lQZFFBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# ascending = False(내림차순), default(오름차순)\n",
        "df['col'].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "1JrAtaxRrgeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 3-1.특정값이 포함된 Data 찾기\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G5fpYbrpFFEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df[df['col'].astype(str).str.contains('text')]"
      ],
      "metadata": {
        "id": "zuL7eaxsrwgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 3-1.상관계수 값 출력\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ElaJf3-RFFIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "stats.pearsonr(x=df['x'], y=df['y'])"
      ],
      "metadata": {
        "id": "cz6mgRCmsBFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 3-2.pairplot 상관관계 분석\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nGZMZzTcFFM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "#  모든 변수 조합에 관한 Scatter plot\n",
        "df_pair = df[['col1', 'col2', 'col3', 'col4']]\n",
        "sns.pairplot(df_pair)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H0o7SS4CsNcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 3-2.Heat map 상관관계 분석 \n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gmaMQO-lFFQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "# 모든 조합, 상관계수 표현\n",
        "df_pair = df[['col1', 'col2', 'col3', 'col4']]\n",
        "sns.heatmap(df_pair.corr(), vmin = -1, vmax = +1, annot = True, cmap = 'coolwarm');"
      ],
      "metadata": {
        "id": "CybqSI-9swCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 3-3.Regressor(회귀) 모델 학습 및 평가\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q3vvk8KxsdBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델링을 학습하기 위한 Fearue(X)와 Y데이터를 구분하는 단계 \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import metrics\n",
        "\n",
        "X=df.drop(['y'], axis=1)\n",
        "Y=df['y']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "# RandomForestRegressor 모델 학습\n",
        "rfr = RandomForestRegressor()\n",
        "rfr.fit(x_train, y_train)\n",
        "\n",
        "# 예측\n",
        "# 예측은 학습에 사용된 Data와 Test Data 모두 예측하고 평가함(※ 과적합 여부 판별)\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "y_pred_train = rfr.predict(x_train)\n",
        "y_pred_test = rfr.predict(x_test)\n",
        "\n",
        "\n",
        "mse_train = mean_absolute_error(y_train, y_pred_train)\n",
        "print('mse_train(mse): ', mse_train)\n",
        "rmse_train = (np.sqrt(mse_train))\n",
        "print('rmse_train(rmse): ', rmse_train)\n",
        "r2_train = r2_score(y_train, y_pred_train)\n",
        "print('rmse_train(r2): ', r2_train)\n",
        "print('')\n",
        "mse_test = mean_absolute_error(y_test, y_pred_test)\n",
        "print('mse_test(mse): ', mse_test)\n",
        "rmse_test = (np.sqrt(mse_test))\n",
        "print('rmse_test(rmse): ', rmse_test)\n",
        "r2_test = r2_score(y_test, y_pred_test)\n",
        "print('rmse_test(r2): ', r2_test)"
      ],
      "metadata": {
        "id": "UxYQcuNws8xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 4-1.sep 활용 csv 파일 읽기\n",
        "---"
      ],
      "metadata": {
        "id": "HTUO2J7dFFUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "pd.read_csv('df.csv', sep=';')"
      ],
      "metadata": {
        "id": "fwE0M2DLtSBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 4-1.특정 조건 만족하는 값, 변경하기\n",
        "---"
      ],
      "metadata": {
        "id": "pUc4kcmysfzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.where(df['col'] <= 5, 1, 0)"
      ],
      "metadata": {
        "id": "8znzLj3ruD8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 4-2.표준화 및 PCA 차원축소\n",
        "---"
      ],
      "metadata": {
        "id": "JYp-8ljasgjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "x = StandardScaler().fit_transform(x)\n",
        "\n",
        "pca = PCA(n_components = 2)\n",
        "principalComponents = pca.fit_transform(x)\n",
        "principalDf = pd.DataFrame(data = principalComponents\n",
        "             , columns = ['principal component 1', 'principal component 2'])"
      ],
      "metadata": {
        "id": "pKF85Z0UuOlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 4-2.전처리 규칙 파이프라인 만들기\n",
        "---"
      ],
      "metadata": {
        "id": "5aTXrzQNsgvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Create scaler: scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Create a PCA instance: pca\n",
        "pca = PCA()\n",
        "\n",
        "# Create pipeline: pipeline\n",
        "pipeline = make_pipeline(scaler,pca)\n",
        "\n",
        "# Fit the pipeline to 'samples'\n",
        "pipeline.fit(df)"
      ],
      "metadata": {
        "id": "rI1yeWQmvMni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 4-2.그래프에 수직, 수평선 추가 및 길이 조절\n",
        "---"
      ],
      "metadata": {
        "id": "A2K1Prwdsg0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.scatterplot(data=df,x='x',y='y', s=50, linewidth=0);\n",
        "\n",
        "# 수직선 추가\n",
        "plt.vlines(-2, ymin=-2, ymax=2, color='r', linewidth=2);\n",
        "plt.vlines(2, ymin=-2, ymax=2, color='r', linewidth=2);\n",
        "\n",
        "# 수평선 추가\n",
        "plt.hlines(-2, xmin=-2, xmax=2, color='r', linewidth=2);\n",
        "plt.hlines(2, xmin=-2, xmax=2, color='r', linewidth=2);"
      ],
      "metadata": {
        "id": "bA5AICpdvcFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 5-3.선형회귀활용 모델링\n",
        "---"
      ],
      "metadata": {
        "id": "PSi0frPnsg4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델링을 학습하기 위한 Fearue(X)와 Y데이터를 구분하는 단계 \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "X=df.drop(['y'], axis=1)\n",
        "Y=df['y']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "# LR(선형회귀) 모델 활용\n",
        "from sklearn.linear_model import LinearRegression\n",
        "mlr = LinearRegression()\n",
        "mlr.fit(x_train, y_train) \n",
        "\n",
        "# 예측\n",
        "# 예측은 학습에 사용된 Data와 Test Data 모두 예측하고 평가함(※ 과적합 여부 판별)\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "y_pred_train = mlr.predict(x_train)\n",
        "y_pred_test = mlr.predict(x_test)\n",
        "\n",
        "# 평가\n",
        "mse_train = mean_absolute_error(y_train, y_pred_train)\n",
        "print('mse_train(mse): ', mse_train)\n",
        "rmse_train = (np.sqrt(mse_train))\n",
        "print('rmse_train(rmse): ', rmse_train)\n",
        "r2_train = r2_score(y_train, y_pred_train)\n",
        "print('rmse_train(r2): ', r2_train)\n",
        "print('')\n",
        "mse_test = mean_absolute_error(y_test, y_pred_test)\n",
        "print('mse_test(mse): ', mse_test)\n",
        "rmse_test = (np.sqrt(mse_test))\n",
        "print('rmse_test(rmse): ', rmse_test)\n",
        "r2_test = r2_score(y_test, y_pred_test)\n",
        "print('rmse_test(r2): ', r2_test)"
      ],
      "metadata": {
        "id": "Y9BG9WMOvrc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 5-3.선형회귀 상관계수 확인\n",
        "---"
      ],
      "metadata": {
        "id": "oMenCWcasg8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_coef = pd.DataFrame({'col':X.columns, 'coef':mlr.coef_}).reset_index(drop=True)\n",
        "df_coef"
      ],
      "metadata": {
        "id": "-XOqBw3iweS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 5-3.light gbm 활용 모델링\n",
        "---"
      ],
      "metadata": {
        "id": "apFB5ehZshBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ▶ 모델링을 학습하기 위한 Fearue(X)와 Y데이터를 구분하는 단계 \n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 세트로드\n",
        "X = df.drop(['y'], axis=1)\n",
        "Y = df['y']\n",
        "\n",
        "# train/test split\n",
        "x_train, x_test, y_train, y_test = train_test_split (X, Y, test_size = 0.3)\n",
        "    \n",
        "# 데이터 세트를 적절한 LGB 형식으로 변환\n",
        "d_train = lgb.Dataset (x_train, label = y_train)\n",
        "\n",
        "# setting the parameters\n",
        "params = {} \n",
        "params [ 'learning_rate'] = 0.02\n",
        "params [ 'boosting_type'] = 'gbdt' # GradientBoostingDecisionTree\n",
        "params['objective'] = 'binary'\n",
        "params [ 'metric' ] = 'binary_logloss' # metric for binary-class\n",
        "params [ 'max_depth'] = 5\n",
        "params [ 'num_leaves' ] = 32\n",
        "params ['seed'] = 23456\n",
        "\n",
        "# 모델 학습\n",
        "clf = lgb.train (params, d_train, 1000) # epocs에서 모델 훈련\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred_train = clf.predict(x_train)\n",
        "for i in range(0,len(y_pred_train)):\n",
        "    if y_pred_train[i]>=.5:       # setting threshold to .5\n",
        "       y_pred_train[i]=1\n",
        "    else:  \n",
        "       y_pred_train[i]=0\n",
        "\n",
        "y_pred_test = clf.predict(x_test)\n",
        "for i in range(0,len(y_pred_test)):\n",
        "    if y_pred_test[i]>=.5:       # setting threshold to .5\n",
        "       y_pred_test[i]=1\n",
        "    else:  \n",
        "       y_pred_test[i]=0\n",
        "\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(classification_report(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "W9i8E9mGwmXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 6-1.연속형, 범주형 변수 list 나누기\n",
        "---"
      ],
      "metadata": {
        "id": "6wlYCH7ZshIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "#  numeric, categorical value 나누기\n",
        "numeric_list=[]\n",
        "categoical_list=[]\n",
        "\n",
        "for i in df.columns :\n",
        "  if df[i].dtypes == 'O' :\n",
        "    categoical_list.append(i)\n",
        "  else :\n",
        "    numeric_list.append(i)"
      ],
      "metadata": {
        "id": "P8gkY_TGw4Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 6-2.catplot 그리기\n",
        "---"
      ],
      "metadata": {
        "id": "1N9LwlxPshSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use(['dark_background'])\n",
        "\n",
        "sns.catplot(x=\"x\", hue=\"y\", kind=\"count\",palette=\"pastel\", edgecolor=\".6\",data=df);\n",
        "plt.gcf().set_size_inches(25, 3)"
      ],
      "metadata": {
        "id": "NHKg37LMxEtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 6-2.groupby 활용 카운팅\n",
        "---"
      ],
      "metadata": {
        "id": "01Co-SJEshWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df['y'].groupby(df['job']).value_counts()"
      ],
      "metadata": {
        "id": "DCpdK00WxO7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 6-2.pivot table 활용 데이터 처리\n",
        "---"
      ],
      "metadata": {
        "id": "muTPChYkshZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_job = pd.pivot_table(df_job,          # 피벗할 데이터프레임\n",
        "                     index = 'index',    # 행 위치에 들어갈 열\n",
        "                     columns = 'col',    # 열 위치에 들어갈 열\n",
        "                     values = 'value')   # 데이터로 사용할 열 "
      ],
      "metadata": {
        "id": "J5EXlHa0yGjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 7-1.pivot table 활용 데이터 처리\n",
        "---"
      ],
      "metadata": {
        "id": "fD9ETIrrshb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "pd.read_excel('chapter07_credit_card_pay.xlsx')"
      ],
      "metadata": {
        "id": "AlVJvvQryRbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 7-1.inf(무한대) 데이터 null 처리\n",
        "---"
      ],
      "metadata": {
        "id": "r1wouD4ssheR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df['col'].replace([np.inf, -np.inf], np.nan)"
      ],
      "metadata": {
        "id": "lkIbWBV7yhGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 7-3.AUROC score 출력하기\n",
        "---"
      ],
      "metadata": {
        "id": "jyKhrNovshgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_pred_train_proba = rfc.predict_proba(x_train)[:, 1] \n",
        "y_pred_test_proba = rfc.predict_proba(x_test)[:, 1] \n",
        "\n",
        "\n",
        "roc_score_train = roc_auc_score(y_train, y_pred_train_proba)\n",
        "roc_score_test = roc_auc_score(y_test, y_pred_test_proba)\n",
        "\n",
        "print(\"roc_score_train :\", roc_score_train)\n",
        "print(\"roc_score_test :\", roc_score_test)"
      ],
      "metadata": {
        "id": "MT80yvSHyy2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 8-2.Unique한 데이터 숫자세기\n",
        "---"
      ],
      "metadata": {
        "id": "c8KeOCBbshin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df['col'].nunique()"
      ],
      "metadata": {
        "id": "zWxe7-g-zJhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 8-3.누적 막대 그래프로 비중 표현\n",
        "---"
      ],
      "metadata": {
        "id": "hDgXQKRJshkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "ax = df.plot(kind='barh', stacked=True, title=\"years amt\", rot=0);\n",
        "for p in ax.patches:\n",
        "    left, bottom, width, height = p.get_bbox().bounds\n",
        "    ax.annotate(\"%.1f\"%(width*100), xy=(left+width/2, bottom+height/2), ha='center', va='center', color='r');\n",
        "\n",
        "plt.box(False)\n",
        "plt.gcf().set_size_inches(10, 5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kqUEhW7Vz5Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 9-1.apply lambda 활용 데이터 split\n",
        "---"
      ],
      "metadata": {
        "id": "e603KgNKshom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df['col'].apply(lambda x: x.split('/')[0])"
      ],
      "metadata": {
        "id": "r2spTo580JU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 9-3.Lable encoder 활용 범주형 데이터 처리\n",
        "---"
      ],
      "metadata": {
        "id": "mtCEQcDrshrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "for col in categoical_list:\n",
        "    print(col)\n",
        "    le = LabelEncoder()\n",
        "    le.fit(list(x_train[col].values) + list(x_test[col].values))\n",
        "    x_train[col] = le.transform(x_train[col])\n",
        "    x_test[col] = le.transform(x_test[col])"
      ],
      "metadata": {
        "id": "mQBpt2Nj0q0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 10-2.연속형 변수의 구간화\n",
        "---"
      ],
      "metadata": {
        "id": "6xWYb1-xshvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "df['df_gp'] = np.where (df['df'] <= 30, 1, \n",
        "                           np.where(df['df'] <= 50, 2, 3))"
      ],
      "metadata": {
        "id": "1f2Cn8EE011K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 10-3.ROC 커브 그리기\n",
        "---"
      ],
      "metadata": {
        "id": "ohZl4qJRshy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "def roc_curve_plot(y_test , pred_proba_c1):\n",
        "    # 임곗값에 따른 FPR, TPR 값을 반환 받음.\n",
        "    # FPR : 암환자가 아닌 환자를 암환자라고 잘 못 예측한 비율\n",
        "    # TPR : Recall\n",
        "    fprs , tprs , thresholds = roc_curve(y_test ,pred_proba_c1)\n",
        "\n",
        "    # ROC Curve를 plot 곡선으로 그림. \n",
        "    plt.plot(fprs , tprs, label='ROC')\n",
        "    # 가운데 대각선 직선을 그림. \n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random', color='red')\n",
        "  \n",
        "    # FPR X 축의 Scale을 0.1 단위로 변경, X,Y 축명 설정등   \n",
        "    start, end = plt.xlim()\n",
        "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
        "    plt.xlim(0,1)\n",
        "    plt.ylim(0,1)\n",
        "    plt.xlabel('FPR( 1 - Sensitivity )')\n",
        "    plt.ylabel('TPR( Recall )')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "roc_curve_plot(y_test, y_pred_test_proba)"
      ],
      "metadata": {
        "id": "rFj-VVLu12Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 11-1.캔들스틱 주식 데이터 그리기\n",
        "---"
      ],
      "metadata": {
        "id": "I1qnyCUlsh2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_finance import candlestick2_ohlc\n",
        "\n",
        "fig = plt.figure(figsize=(20,5))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "df_100 = df.iloc[0:30,:]\n",
        "df_100 =df_100.set_index('Date')\n",
        "index = df_100.index.astype('str')\n",
        "\n",
        "ax.plot(index, df_100['Close'], label='Close', linewidth=0.7)\n",
        "\n",
        "candlestick2_ohlc(ax, df_100['Open'], df_100['High'], \n",
        "                  df_100['Low'], df_100['Close'],\n",
        "                  width=0.5, colorup='r', colordown='b');\n",
        "plt.xticks(rotation=45)\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "fCXAYNvO19nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 11-2.그래프 특정 값에 색상 입히기\n",
        "---"
      ],
      "metadata": {
        "id": "bbbSnBNash5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['vol_color'] = np.where(df['Volume_issue']==1, 'red', 'gray')\n",
        "colors=list(df['vol_color'])\n",
        "print(colors)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(df['Date'], df['Close'], 'o-', ms=1, lw=0.5, label='Close')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.bar(df['Date'], df['Volume'], label='volume', color=colors)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "hkmTRhT_282S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 11-3.lag 데이터 생성\n",
        "---"
      ],
      "metadata": {
        "id": "P_qbAAqksh8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# + n : 순반향, - n : 역방향\n",
        "df['col'].shift(1)"
      ],
      "metadata": {
        "id": "Q7SFZvcQ3Nzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 12-1.중복 데이터 처리\n",
        "---"
      ],
      "metadata": {
        "id": "lF1n5Mgmsh_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df.drop_duplicates(['col'], keep = 'first', inplace=True)"
      ],
      "metadata": {
        "id": "m-0xlBcl3lr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 12-3.회귀예측 문제 실제값, 예측값 fitting 확인\n",
        "---"
      ],
      "metadata": {
        "id": "HBB5U4Rf2DAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "result = pd.DataFrame({'Real Values':y_test, 'Predicted Values':y_pred_test})\n",
        "result['diff'] = result['Real Values'] - result['Predicted Values']\n",
        "\n",
        "sns.scatterplot(result['Real Values'], result['Predicted Values'])\n",
        "plt.gcf().set_size_inches(10 ,10)"
      ],
      "metadata": {
        "id": "fy2MCmET3zE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 13-1.한글 깨질시 데이터 읽기\n",
        "---"
      ],
      "metadata": {
        "id": "Qorzi48O2DDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ▶ Data read\n",
        "import pandas as pd \n",
        "pd.read_csv('chapter13_congestion.csv', encoding='cp949')"
      ],
      "metadata": {
        "id": "NHBWt7sJ3_EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 13-1.문자열 데이터 앞 공백 제거\n",
        "---"
      ],
      "metadata": {
        "id": "oPbV7qNy2DJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df['col'].str.lstrip()"
      ],
      "metadata": {
        "id": "xxeWdAIk4N6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 14-1.위도, 경도 활용 특정 좌표 Mapping\n",
        "---"
      ],
      "metadata": {
        "id": "8hns3vWx2DPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "m = folium.Map(location=[38.8043, -77.0611], zoom_start=12)"
      ],
      "metadata": {
        "id": "49xe_tIN4bSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 14-1.위도, 경도 특정 좌효 Marker 그리기\n",
        "---"
      ],
      "metadata": {
        "id": "bX-65qS62DRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "\n",
        "m = folium.Map(location=[29.5978, -95.3524], zoom_start=12)\n",
        "\n",
        "for i in df_city.index:\n",
        "    sub_lat =  df_city.loc[i,'latitude']\n",
        "    sub_long = df_city.loc[i,'longitude']\n",
        "    \n",
        "    title = df_city.loc[i,'city']\n",
        "    \n",
        "    # 지도에 데이터 찍어서 보여주기\n",
        "    folium.Marker([sub_lat,sub_long],tooltip = title).add_to(m)\n",
        "\n",
        "# Display the map\n",
        "m"
      ],
      "metadata": {
        "id": "NUFJFs-C4brk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 14-1.Marker 클러스터 생성\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HdZphtBy2DU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "from folium import Marker\n",
        "from folium.plugins import MarkerCluster\n",
        "\n",
        "# Base map 설정\n",
        "m = folium.Map(location=[29.5978, -95.3524], tiles='openstreetmap', zoom_start=11)\n",
        "\n",
        "# Marker cluster (위도, 경도, 제목)\n",
        "mc = MarkerCluster()\n",
        "for _, row in df_city.iterrows():\n",
        "    mc.add_child(    \n",
        "        Marker(location = [row['latitude'], row['longitude']],\n",
        "               popup=row['street_address']\n",
        "              )\n",
        "    )\n",
        "    \n",
        "m.add_child(mc)\n",
        "\n",
        "# Display the map\n",
        "m"
      ],
      "metadata": {
        "id": "EVmKsXl44rSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 14-2.데이터 left join\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zMEw8hhs2Dax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.merge(df1, df2, how='left', on='state')"
      ],
      "metadata": {
        "id": "rFAQ-wvy42fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 14-3.Circle Marker 그리기\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KTCsS4fI2DeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from folium import Marker\n",
        "from folium.plugins import MarkerCluster\n",
        "\n",
        "df_DE = df[df['state']=='CA']\n",
        "\n",
        "# ▶ Draw a basemap\n",
        "m = folium.Map(location=[34.1515, -118.0018], tiles='openstreetmap', zoom_start=11)\n",
        "\n",
        "# ▶ Add  points to the map\n",
        "mc = MarkerCluster()\n",
        "for _, row in df_DE.iterrows():\n",
        "    mc.add_child(    \n",
        "        Marker(location = [row['latitude'], row['longitude']],\n",
        "               popup=row['street_address']\n",
        "              )\n",
        "    )\n",
        "        \n",
        "m.add_child(mc)\n",
        "\n",
        "# Circle Marker 추가 \n",
        "folium.CircleMarker(\n",
        "  [34.1515, -118.0018],\n",
        "  radius=100,\n",
        "  color='#ffffgg',\n",
        "  fill_color='#fffggg',\n",
        "  popup='New_in'\n",
        ").add_to(m)\n",
        "\n",
        "# ▶ Display the map\n",
        "m"
      ],
      "metadata": {
        "id": "rGyr9UMX5A8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 15-1.Recency(최근성) 데이터 생성\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "MuLRbJ2U2Dg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "# Dt_Customer은 날짜 데이터여야함\n",
        "df['Dt_Customer'] = df['Dt_Customer'].apply(lambda x : (df['Dt_Customer'].max() - x).days)\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "hvTYaVUa5QQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 15-1.groupby.agg 활용 타겟률 추출\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5ec5679o2Djj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "df_mkt_gp = df_mkt.groupby('group')['Response'].agg(['count','sum'])\n",
        "df_mkt_gp['ratio'] = round((df_mkt_gp['sum'] / df_mkt_gp['count']) * 100, 1)\n",
        "df_mkt_gp"
      ],
      "metadata": {
        "id": "IsghJnqn5Qlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 16-1.연관규칙 분석을 위한 list 데이터처리\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ttNm6JpM2Dmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "\n",
        "records = []\n",
        "for i in range(len(df)):\n",
        "    records.append([str(df.values[i,j]) for j in range(len(df.columns)) if not pd.isna(df.values[i,j])])"
      ],
      "metadata": {
        "id": "ys1a61e65wO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 16-1.Transaction Encoder 활용 전처리\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "fLkB4v8y2DqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(records).transform(records)\n",
        "\n",
        "te_df = pd.DataFrame(te_ary, columns=te.columns_)"
      ],
      "metadata": {
        "id": "nf1zTz3b5z5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 16-2.연관규칙 생성\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "E5GnVV1V5RNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "frequent_itemset = apriori(te_df,\n",
        "                           min_support=0.005, \n",
        "                           max_len=3, \n",
        "                           use_colnames=True)\n",
        "\n",
        "frequent_itemset['length'] = frequent_itemset['itemsets'].map(lambda x: len(x))\n",
        "frequent_itemset.sort_values('support',ascending=False,inplace=True)"
      ],
      "metadata": {
        "id": "A9LBXZwQ53gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 16-2.연관규칙 분석\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dXhgLtiH5RRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "association_rules_df = association_rules(frequent_itemset, \n",
        "                                         metric='confidence', \n",
        "                                         min_threshold=0.005,)"
      ],
      "metadata": {
        "id": "VIrL1oku56Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 17-3.다항회귀(비선형 패턴) 모델링\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GsAVrYmP5RTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ▶ 모델링을 학습하기 위한 Fearue(X)와 Y데이터를 구분하는 단계\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "X=df1.drop(['Store', 'Date', 'Weekly_Sales'], axis=1)\n",
        "Y=df1['Weekly_Sales']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=1239)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, include_bias=True)\n",
        "\n",
        "X_train_poly = poly.fit_transform(x_train)\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train_poly, y_train)\n",
        "\n",
        "X_test_poly = poly.transform(x_test)\n",
        "\n",
        "y_pred_test = lin_reg.predict(X_test_poly)\n",
        "\n",
        "\n",
        "mse_test = mean_absolute_error(y_test, y_pred_test)\n",
        "print('mse_test(mse): ', mse_test)\n",
        "rmse_test = (np.sqrt(mse_test))\n",
        "print('rmse_test(rmse): ', rmse_test)\n",
        "r2_test = r2_score(y_test, y_pred_test)\n",
        "print('rmse_test(r2): ', r2_test)"
      ],
      "metadata": {
        "id": "wMBZblI16S7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 17-3.선형 Fitting 확인 및 그래프 그리기\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CSJ5bZ7X5RZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# xlim과 ylim을 데이터 range에 맞춰 동일한 값으로 설정\n",
        "sns.scatterplot(result['Real Values'], result['Predicted Values'])\n",
        "plt.xlim(1400000, 2400000)\n",
        "plt.ylim(1400000, 2400000)\n",
        "x = [1400000, 2400000]\n",
        "y = [1400000, 2400000]\n",
        "plt.plot(x, y, color='red')\n",
        "plt.gcf().set_size_inches(5 ,5)"
      ],
      "metadata": {
        "id": "y2AkHk2Z6dru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 18-1.특정 Col 기준으로 Drop\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5KUW4Mo_5R9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "\n",
        "df.dropna(subset=['CustomerID'], how='all', inplace=True)"
      ],
      "metadata": {
        "id": "jdzUSLF66sDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 18-2.RFM 분석\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LzF5p5_t5SAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "\n",
        "# 고객의 마지막 구매일 구하기\n",
        "recency_df = df.groupby('CustomerID',as_index=False)['Date'].max()\n",
        "recency_df.columns = ['CustomerID','LastPurchaseDate']\n",
        "recency_df.head()\n",
        "\n",
        "# 고객의 가장 마지막 구매일로 부터 몇일이 지났는지를 계산하기 위함\n",
        "recency_df['Recency'] = recency_df['LastPurchaseDate'].apply(lambda x : (df['Date'].max() - x).days)\n",
        "recency_df.drop(columns=['LastPurchaseDate'],inplace=True)\n",
        "\n",
        "\n",
        "# Customer ID당 유니크한 Invoice를 1개의 주문건으로 인식하여 얼마나 자주 구매하고 있는지를 파악 \n",
        "frequency_df = df.copy()\n",
        "frequency_df.drop_duplicates(subset=['CustomerID','InvoiceNo'], keep=\"first\", inplace=True) \n",
        "frequency_df = frequency_df.groupby('CustomerID', as_index=False)['InvoiceNo'].count()\n",
        "frequency_df.columns = ['CustomerID','Frequency']\n",
        "\n",
        "\n",
        "# 구매금액 = 구매개수 * 구매단가\n",
        "df['Total_cost'] = df['UnitPrice'] * df['Quantity']\n",
        "monetary_df=df.groupby('CustomerID',as_index=False)['Total_cost'].sum()\n",
        "monetary_df.columns = ['CustomerID','Monetary']\n"
      ],
      "metadata": {
        "id": "ccub4uoI6vIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 18-3.min-max scale 활용 표준화\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "aI2j6Wds5SDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import minmax_scale\n",
        "\n",
        "rfm['Recency'] = minmax_scale(rfm['Recency'], axis=0, copy=True)"
      ],
      "metadata": {
        "id": "john3bEF6yxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 18-3.날짜 데이터 형식 변경\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dZy874Mf5SFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "df[\"Date\"].dt.strftime(\"%Y-%m\")"
      ],
      "metadata": {
        "id": "rEXIv-Td61ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 19-1.index 순서 변경하기\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "g8rL_XyZ5SHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(df['Month'].value_counts(), index=['Feb', 'Mar', 'May', 'June', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])"
      ],
      "metadata": {
        "id": "OUd3WVmI7rT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 20-2.시계열 분해\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "iRF2iJkN5SJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "%matplotlib inline\n",
        "plt.style.use(['dark_background'])\n",
        "\n",
        "# 덧셈 분해 (additive decomposition) \n",
        "\n",
        "res = seasonal_decompose(df['M3'],model='addictive')\n",
        "res.plot()\n",
        "plt.gcf().set_size_inches(20, 7)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 곱셈 분해 (multiplicative decomposition)\n",
        "res = seasonal_decompose(df['M3'],model='multiplicative')\n",
        "ax=res.plot()\n",
        "plt.gcf().set_size_inches(20, 7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h9TzRqFJ7zb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 20-3.Seasonal Arima 활용 시계열 예측\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yF0wYLS664ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the p, d and q parameters to take any value between 0 and 2\n",
        "p = d = q = range(0, 2)\n",
        "\n",
        "# Generate all different combinations of p, q and q triplets\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "\n",
        "# Generate all different combinations of seasonal p, q and q triplets\n",
        "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
        "\n",
        "print('Examples of parameter combinations for Seasonal ARIMA...')\n",
        "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\n",
        "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\n",
        "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\n",
        "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))\n",
        "\n",
        "# ▶ 모든 조합의 Parameter 모델 생성 후 AIC로 모델 성능 파악 (※ AIC가 작을수록 최적의 모델일 확률이 높다)\n",
        "# ▶ 1년 단위 데이터이기 때문에 주기가 12\n",
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "np.random.seed(1234)\n",
        "warnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n",
        "cols = ['param','param_seasonal','aic']\n",
        "lst = []\n",
        "for param in pdq:\n",
        "    for param_seasonal in seasonal_pdq:\n",
        "        try:\n",
        "            mod = sm.tsa.statespace.SARIMAX(df,\n",
        "                                            order=param,\n",
        "                                            seasonal_order=param_seasonal,\n",
        "                                            enforce_stationarity=False,\n",
        "                                            enforce_invertibility=False)\n",
        "            results = mod.fit()\n",
        "            \n",
        "            print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n",
        "            lst.append([param, param_seasonal, results.aic])\n",
        "            df1 = pd.DataFrame(lst, columns=cols)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "\n",
        "# ▶ AIC가 최소가 되는 parameter 조합 \n",
        "aic_min=df1['aic'].min()\n",
        "optimal_para=df1.loc[df1['aic']==aic_min]\n",
        "optimal_para\n",
        "\n",
        "# ▶ Best score 기준 모델 학습\n",
        "mod = sm.tsa.statespace.SARIMAX(df,\n",
        "                                order=(0,1,1),\n",
        "                                seasonal_order=(0,1,1,12),\n",
        "                                enforce_stationarity=False,\n",
        "                                enforce_invertibility=False)\n",
        "results = mod.fit()\n",
        "print(results.summary().tables[1])\n",
        "\n",
        "# ▶ Ljung-Box : 잔차가 White noise를 따르는지 (※ 시계열 모형이 잘 적합되었고 남은 잔차는 더이상 자기상관을 가지지 않는 백색 잡음)\n",
        "# ▶ Jarque-Bera : 잔차의 분포가 normal distributison을 따르는지\n",
        "# ▶ Hereroskeddasticity : 시간대별 잔차의 분산이 일정한지\n",
        "# ▶ 모두 0.05 이상이므로 White noise를 따르며, normal distribution이며, 분산이 일정하다.\n",
        "results.summary()\n",
        "\n",
        "# ▶ 생성된 모델 정합성 확인 과정 (※ Arima 모델을 사용할 수 있는지 판단하는 것, 잔차가 정상성을 따르는지)\n",
        "results.plot_diagnostics(figsize=(15, 12))\n",
        "plt.show()\n",
        "\n",
        "# ▶ (1) Standardized residual : 잔차가 백색잡음(White noise)에 가까울 수록 좋음, 평균 0을 중심으로 백색잡음의 형태 \n",
        "# ▶ (2) Histogram plus estimated density : 잔차의 분포가 정규분포를 따르는지, 잔차의 히스토그램과 KDE plot을 그리고, N(0,1) 정규분포와 비교\n",
        "# ▶ (3) Q-Q plot : 두개의 분포가 같은지 다른지 판단하는 Plot (x축 :이론적 샘플분포(정규분포), y축 : df['M3])\n",
        "# ▶ (4) Correlogram(콜렐로그램) : 잔차에대한 ACF, 예측된 자기상관성을 나타내기 위한 Plot, 초록색 Box 안에 들어와 있으면 자기상관성이 없다고 판단할 수 있음\n",
        "\n",
        "# ▶ 약간의 정규성을 벗어난다, 예측 후 잘 맞지 않으면 파라미터 수정 후 재 진행"
      ],
      "metadata": {
        "id": "vZRDTSWA75-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 21-1.list 중복 없애기\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xt7kE8ff64yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "all_list = list(df['start']) + list(df['end'])\n",
        "unique_list = set(all_list)"
      ],
      "metadata": {
        "id": "2lgKG8TH8QCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 21-2.for문 활용 dataframe 생성\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "O0bkv7Hi649C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "\n",
        "list_of_df = [] \n",
        "\n",
        "for i in list(df['start'].unique()) :\n",
        "  loop_df = pd.DataFrame(df[df['start']==i].groupby('prod')['cnt'].sum().sort_values(ascending=False)).reset_index().head(1)\n",
        "  loop_df['id'] = i\n",
        "  list_of_df.append(loop_df)\n",
        "\n",
        "df_accum_start = pd.concat(list_of_df) "
      ],
      "metadata": {
        "id": "Rk2o6qbU8SY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 24-1.for문 활용 dataframe 생성\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zqiGut_x65TO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# barplot, order 옵션을 활용하여 가독성 Up\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "plt.style.use(['dark_background'])\n",
        "\n",
        "sns.barplot(x='arrival_date_month', y='hotel', hue='arrival_date_year', data = df_reservation,\n",
        "            order = ['01.January', '02.February', '03.March', '04.April', '05.May', '06.June', '07.July', '08.August', '09.September', '10.October', '11.November', '12.December']);\n",
        "plt.gcf().set_size_inches(20, 5);"
      ],
      "metadata": {
        "id": "pwueJzIc9F_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 25-1.pandas dataframe 시각적 표현 Tip\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HpXdbYnS65V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "# 시각적 표현 Tip\n",
        "df_gp_ratio = df_gp[['ratio']]\n",
        "df_gp_ratio.style.background_gradient(cmap='Reds')"
      ],
      "metadata": {
        "id": "AAJyVo6Y9LC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 28-3.t-test 활용 A/B test\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "lolcbmDQ65ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "tstat, pvalue = stats.ttest_ind(df[df.version == 'gate_30'].sum_gamerounds, df[df.version == 'gate_40'].sum_gamerounds, equal_var=False)\n",
        "print(f'p-value: {pvalue:.4f}')"
      ],
      "metadata": {
        "id": "R5VyMIY29NzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 28-3.chi2 test 활용 A/B test\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QFQu6YRn65is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "chi2, p_value, df, _ = stats.chi2_contingency(df_pivot_1)\n",
        "print(f'p-value for single sided test: {p_value / 2:.4f}')"
      ],
      "metadata": {
        "id": "8NlhZ1et9O9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ch 29-2.isin, notnull 활용 데이터 찾기\n",
        "---"
      ],
      "metadata": {
        "id": "CwdrsY_y65nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# voice actor의 경우 중복 데이터가 많기 때문에 Hero에 성우와 Villian의 성우만 join \n",
        "hero_list = list(df_merge[df_merge['hero'].notnull()]['hero'])\n",
        "Villian_list = list(df_merge[df_merge['villian'].notnull()]['villian'])\n",
        "\n",
        "\n",
        "# 주인공 성우도 2명이 진행한 이력이 있다.\n",
        "df_voice_actor[df_voice_actor['character'].isin(hero_list)]['movie_title'].value_counts().head(5)"
      ],
      "metadata": {
        "id": "MuIoh8HS9XDI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}